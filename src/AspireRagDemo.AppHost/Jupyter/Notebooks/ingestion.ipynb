{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c64f80-e612-48b0-b4b1-bf3e0be2595a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.instrumentation.instrumentor:Attempting to instrument while already instrumented\n",
      "WARNING:opentelemetry.instrumentation.instrumentor:Attempting to instrument while already instrumented\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# allow loading modules from local directory.\n",
    "sys.path.insert(1, '/home/jovyan/work/code')\n",
    "\n",
    "from opentelemetry import trace\n",
    "from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.resources import SERVICE_NAME, Resource\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "from opentelemetry.instrumentation.langchain import LangchainInstrumentor\n",
    "\n",
    "# Logging (Experimental)\n",
    "from opentelemetry._logs import set_logger_provider\n",
    "from opentelemetry.exporter.otlp.proto.grpc._log_exporter import (\n",
    "    OTLPLogExporter,\n",
    ")\n",
    "from opentelemetry.sdk._logs import LoggerProvider, LoggingHandler\n",
    "from opentelemetry.sdk._logs.export import BatchLogRecordProcessor\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "\n",
    "#from otel_grpc import configure_otel_otlp\n",
    "\n",
    "from config import VectorDBConfig, EmbeddingConfig, ProcessingConfig, ChatConfig\n",
    "from pipeline import DocumentPipeline\n",
    "from localrag import LocalRAG\n",
    "\n",
    "import nest_asyncio\n",
    "import asyncio \n",
    "import logging\n",
    "\n",
    "# Enable nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Initialise and Setup OpenTelemetry for the session\n",
    "resource = Resource(attributes={\n",
    "  SERVICE_NAME:  os.getenv('OTEL_SERVICE_NAME', 'jupyter-demo')\n",
    "})\n",
    "provider = TracerProvider(resource=resource)\n",
    "processor = BatchSpanProcessor(OTLPSpanExporter(endpoint=os.getenv(\"OTEL_EXPORTER_OTLP_ENDPOINT\")))\n",
    "provider.add_span_processor(processor)\n",
    "trace.set_tracer_provider(provider)\n",
    "\n",
    " # Configure Logging\n",
    "#configure_otel_otlp( os.getenv('OTEL_SERVICE_NAME', 'jupyter-demo'), endpoint=os.getenv(\"OTEL_EXPORTER_OTLP_ENDPOINT\"))\n",
    "\n",
    "logger_provider = LoggerProvider(\n",
    "    resource=resource\n",
    ")\n",
    "set_logger_provider(logger_provider)\n",
    "\n",
    "exporter = OTLPLogExporter(insecure=True)\n",
    "logger_provider.add_log_record_processor(BatchLogRecordProcessor(exporter))\n",
    "handler = LoggingHandler(level=logging.NOTSET, logger_provider=logger_provider)\n",
    "\n",
    "# Attach OTLP handler to root logger\n",
    "logging.getLogger().addHandler(handler)\n",
    "\n",
    "# logging.basicConfig()\n",
    "#logging.basicConfig(format = \"%(asctime)s:%(levelname)s:%(message)s\", level = logging.DEBUG)\n",
    "logging.root.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "LangchainInstrumentor().instrument()\n",
    "logger = logging.getLogger(__name__)\n",
    "tracer = trace.get_tracer(__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d64272a1-7eed-49e5-8b17-67880bf35215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorDBConfig(url='http://qdrant:6333', api_key='zCxfEnC2RPCH1r64RPqtnY', collection_name='embedding-demo-aspire-inc-yml')\n",
      "EmbeddingConfig(model_name='nomic-embed-text', base_url='http://ollama:11434')\n",
      "ChatConfig(model_name='gemma2:2b', base_url='http://ollama:11434')\n"
     ]
    }
   ],
   "source": [
    "# Get the connection strings and configuration passed from Aspire AppHost\n",
    "\n",
    "def parse_ollama_connection(conn_str):\n",
    "    parts = conn_str.split(';')\n",
    "    endpoint = next(p.split('=')[1] for p in parts if p.startswith('Endpoint='))\n",
    "    model = next(p.split('=')[1] for p in parts if p.startswith('Model='))\n",
    "    return endpoint, model\n",
    "\n",
    "chat_conn = os.getenv('ConnectionStrings__chat-model', 'Endpoint=http://ollama:11434;Model=phi3.5')\n",
    "chat_model_url, chat_model_id = parse_ollama_connection(chat_conn)\n",
    "\n",
    "embeddings_conn = os.getenv('ConnectionStrings__embedding-model', 'Endpoint=http://ollama:11434;Model=mxbai-embed-large')\n",
    "embedding_model_url, embeddings_model = parse_ollama_connection(embeddings_conn)\n",
    "\n",
    "qdrant_conn = os.getenv('ConnectionStrings__qdrant_http', 'Endpoint=http://qdrant:6334;Key=aMjJKx0t1a6E9hysaCacWz')\n",
    "parts = qdrant_conn.split(';')\n",
    "qdrant_url = next(p.split('=')[1] for p in parts if p.startswith('Endpoint='))\n",
    "qdrant_key = next(p.split('=')[1] for p in parts if p.startswith('Key='))\n",
    "\n",
    "vector_db_config = VectorDBConfig(\n",
    "    url=qdrant_url,\n",
    "    api_key=qdrant_key,\n",
    "    collection_name=\"embedding-demo-aspire-inc-yml\"\n",
    ")\n",
    "chat_config = ChatConfig(\n",
    "    model_name=chat_model_id,\n",
    "    base_url=chat_model_url\n",
    ")\n",
    "embedding_config = EmbeddingConfig(\n",
    "    model_name=embeddings_model,\n",
    "    base_url=embedding_model_url\n",
    ")\n",
    "processing_config = ProcessingConfig(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    add_metadata=True,\n",
    "    extract_code_entities=True\n",
    ")\n",
    "\n",
    "print(vector_db_config)\n",
    "print(embedding_config)\n",
    "print(chat_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d757e336-7b98-44af-ae16-716b15d446bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/code/pipeline.py:59: UserWarning: Api key is used with an insecure connection.\n",
      "  self.qdrant = QdrantClient(url=vector_db_config.url, api_key=vector_db_config.api_key)\n",
      "INFO:httpx:HTTP Request: GET http://qdrant:6333/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://ollama:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://qdrant:6333/collections/embedding-demo-aspire-inc-yml/exists \"HTTP/1.1 200 OK\"\n",
      "INFO:IngestionPipeline:Collection embedding-demo-aspire-inc-yml already exists\n",
      "INFO:httpx:HTTP Request: GET http://qdrant:6333/collections/embedding-demo-aspire-inc-yml \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://ollama:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m repository\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/dotnet/docs-aspire\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mstart_as_current_span(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting ingesting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepository\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_repository\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepository\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Or process local directory\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#pipeline.process_local_directory(\"./docs\")\u001b[39;00m\n",
      "File \u001b[0;32m~/work/code/pipeline.py:99\u001b[0m, in \u001b[0;36mDocumentPipeline.process_repository\u001b[0;34m(self, repo_url)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Process a repository and store its documents in the vector store.\"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer\u001b[38;5;241m.\u001b[39mstart_as_current_span(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess repository\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m#print(inspect.getfullargspec(ingest))\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# FullArgSpec(args=['source', 'max_file_size', 'include_patterns', 'exclude_patterns', 'output'],\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m     summary, tree, content \u001b[38;5;241m=\u001b[39m \u001b[43mingest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_patterns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*.md\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*.yml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(summary)\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# 4. Process and index the repository\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/gitingest/ingest.py:14\u001b[0m, in \u001b[0;36mingest\u001b[0;34m(source, max_file_size, include_patterns, exclude_patterns, output)\u001b[0m\n\u001b[1;32m     12\u001b[0m query \u001b[38;5;241m=\u001b[39m parse_query(source, max_file_size, \u001b[38;5;28;01mFalse\u001b[39;00m, include_patterns, exclude_patterns)        \n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m query[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 14\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclone_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m summary, tree, content \u001b[38;5;241m=\u001b[39m ingest_from_query(query)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/nest_asyncio.py:115\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     heappop(scheduled)\n\u001b[1;32m    110\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[1;32m    113\u001b[0m         scheduled[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_when \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_events(event_list)\n\u001b[1;32m    118\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock_resolution\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/selectors.py:468\u001b[0m, in \u001b[0;36mEpollSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    466\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 468\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Ingest a GitHub repository and import into our vector store\n",
    "\n",
    "# Initialize the pipeline\n",
    "pipeline = DocumentPipeline(\n",
    "    vector_db_config=vector_db_config,\n",
    "    embedding_config=embedding_config, \n",
    "    processing_config=processing_config\n",
    ")\n",
    "\n",
    "###Process git repository\n",
    "repository=\"https://github.com/dotnet/docs-aspire\"\n",
    "with tracer.start_as_current_span(f\"Starting ingesting {repository}\"):\n",
    "    pipeline.process_repository(repository)\n",
    "\n",
    "# Or process local directory\n",
    "#pipeline.process_local_directory(\"./docs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6855ef1f-7eca-4c4b-897d-e00d786b8c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/code/localrag.py:46: UserWarning: Api key is used with an insecure connection.\n",
      "  self.qdrant = QdrantClient(url=vector_db_config.url, api_key=vector_db_config.api_key)\n",
      "INFO:httpx:HTTP Request: GET http://qdrant:6333/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://qdrant:6333/collections/embedding-demo-aspire-inc-yml \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://ollama:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://ollama:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://qdrant:6333/collections/embedding-demo-aspire-inc-yml/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Why should I know about .Net Aspire?\n",
      "\n",
      "Relevant chunks:\n",
      "\n",
      "Generated Answer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://ollama:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://ollama:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://qdrant:6333/collections/embedding-demo-aspire-inc-yml/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You should know about .NET Aspire because it is a set of powerful tools, templates, and packages designed to help you build observable, production-ready applications that are optimized for cloud-native environments. \n",
      "\n",
      "Here's why it matters:\n",
      "\n",
      "* **Observable Applications:**  It makes your applications easily trackable and monitor their performance using tools like Grafana and Prometheus. This helps in understanding how the application works under different conditions.\n",
      "* **Cloud-Native Focus:** .NET Aspire was created specifically to support cloud-native development. It offers tools and patterns tailored to the challenges of running distributed, microservice-based applications. \n",
      "* **Orchestration Support:** It simplifies the process of managing your application's dependencies and connections for local development environments, helping you structure and run multi-project apps effectively.\n",
      "\n",
      "Essentially, .NET Aspire aims to make cloud-native development more efficient, easier, and more scalable.  \n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Question: Is .Net Aspire an alternative to Kubernetes?\n",
      "\n",
      "Relevant chunks:\n",
      "\n",
      "Generated Answer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://ollama:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, .NET Aspire is not an alternative to Kubernetes.  \n",
      "\n",
      "Here's why:\n",
      "\n",
      "* **Kubernetes:** A powerful orchestrator that manages containerized applications across multiple machines (nodes). It focuses on deploying and scaling containers. \n",
      "* **.NET Aspire:**  A development platform built upon Tye. It enables the creation of distributed applications with simplified orchestration. While it can be used to deploy to Kubernetes, it's not a direct replacement for Kubernetes itself. \n",
      "\n",
      "Think of it this way: .NET Aspire helps you build and manage your application on top of Kubernetes.  Kubernetes is the underlying platform that handles container orchestration and scaling. \n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test our RAG Solution\n",
    "\n",
    "def demonstrate_local_rag(rag):\n",
    "    \"\"\"Demonstrate how to use the LocalRAG class.\"\"\"    \n",
    "    # Example questions to test\n",
    "    questions = [\n",
    "        \"Why should I know about .Net Aspire?\",\n",
    "        \"Is .Net Aspire an alternative to Kubernetes?\"\n",
    "    ]\n",
    "    with tracer.start_as_current_span(\"Entering questions loop.\"):\n",
    "        for question in questions:\n",
    "            print(f\"Question: {question}\")\n",
    "            print(\"\\nRelevant chunks:\")\n",
    "            #with tracer.start_as_current_span(\"rag get chunks\"):\n",
    "            # chunks = rag.get_relevant_chunks(question, k=5)\n",
    "            # for i, chunk in enumerate(chunks, 1):\n",
    "            #     print(f\"\\nChunk {i}:\")\n",
    "            #     print(f\"Source: {chunk.metadata.get('file_path', 'Unknown')}\")\n",
    "            #      print(f\"Content: {chunk.page_content[:200]}...\")\n",
    "                \n",
    "            print(\"\\nGenerated Answer:\")\n",
    "            with tracer.start_as_current_span(\"Retrieve answers.\"):\n",
    "                answer = rag.retrieve_and_answer(question, k=6)\n",
    "                print(answer)\n",
    "                print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "rag = LocalRAG(\n",
    "    vector_db_config=vector_db_config,\n",
    "    embedding_config=embedding_config, \n",
    "    chat_config=chat_config\n",
    ")\n",
    "with tracer.start_as_current_span(\"Starting demo\"):\n",
    "    demonstrate_local_rag(rag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03d601-a3d6-4de9-80c9-6109d86594a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
