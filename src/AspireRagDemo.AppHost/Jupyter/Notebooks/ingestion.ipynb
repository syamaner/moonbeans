{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4950258f-1d22-49ac-822e-8022e29bba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is  used to evaluate perofrmance of our RAG ingestion and query pipeline.\n",
    "# Method:\n",
    "#   - Generated test data using a sample GitHub repository (offline process not in this notebook)\n",
    "#     - https://docs.ragas.io/en/stable/getstarted/rag_testset_generation/\n",
    "#   - Use our ingestion pipeline to parse the same reporisiroty and index in our vector store\n",
    "#   - Use RAGAS on teadt dataset + our answers fromn our RAG and visualise the mterics.\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(1, '/home/jovyan/work/code')\n",
    "from opentelemetry import trace\n",
    "from config import VectorDBConfig, EmbeddingConfig, ProcessingConfig, ChatConfig\n",
    "from config_helper import ConfigHelper\n",
    "from pipeline import DocumentPipeline\n",
    "from localrag import LocalRAG\n",
    "import nest_asyncio\n",
    "import asyncio \n",
    "import logging\n",
    " \n",
    "# Enable nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# We are using Aspire. Of course we will see the telemetry and logs in our dashboard!\n",
    "# see config_helper.py for the not to tidy details.\n",
    "tracer = trace.get_tracer(__name__)\n",
    "\n",
    "config_helper = ConfigHelper(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d757e336-7b98-44af-ae16-716b15d446bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/code/pipeline.py:37: UserWarning: Api key is used with an insecure connection.\n",
      "  self.qdrant = QdrantClient(url=vector_db_config.url, api_key=vector_db_config.api_key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parts found: 439\n",
      "Total files processed: 219\n",
      "Sample file paths:\n",
      " 1. README.md\n",
      " 2. CODE_OF_CONDUCT.md\n",
      " 3. SECURITY.md\n",
      "Added 1 chunks for file .pre-commit-config.yaml\n",
      "Added 22 chunks for file .repoman.yml\n",
      "Added 72 chunks for file docs/index.yml\n",
      "Added 73 chunks for file docs/toc.yml\n",
      "Added 2 chunks for file docs/breadcrumb/toc.yml\n",
      "Added 5 chunks for file docs/compatibility/toc.yml\n",
      "Added 50 chunks for file docs/reference/aspire-faq.yml\n",
      "Added 18 chunks for file docs/whats-new/index.yml\n",
      "Added 6 chunks for file docs/whats-new/toc.yml\n",
      "Added 7 chunks for file docs/zones/zone-pivot-groups.yml\n",
      "Added 186 chunks for file .github/dependabot.yml\n",
      "Added 3 chunks for file .github/ISSUE_TEMPLATE/01-general-issue.yml\n",
      "Added 9 chunks for file .github/ISSUE_TEMPLATE/02-docs-request.yml\n",
      "Added 5 chunks for file .github/ISSUE_TEMPLATE/03-customer-support.yml\n",
      "Added 12 chunks for file .github/ISSUE_TEMPLATE/04-breaking-change.yml\n",
      "Added 8 chunks for file .github/ISSUE_TEMPLATE/05-community-toolkit-docs-request.yml\n",
      "Added 3 chunks for file .github/ISSUE_TEMPLATE/config.yml\n",
      "Added 7 chunks for file .github/ISSUE_TEMPLATE/z-customer-feedback.yml\n",
      "Added 7 chunks for file .github/policies/auto-merge.yml\n",
      "Added 8 chunks for file .github/policies/label-issues.yml\n",
      "Added 16 chunks for file .github/policies/label-prs.yml\n",
      "Added 3 chunks for file .github/policies/scheduled-prs.yml\n",
      "Added 4 chunks for file .github/workflows/check-for-build-warnings.yml\n",
      "Added 8 chunks for file .github/workflows/clean-repo.yml\n",
      "Added 11 chunks for file .github/workflows/create-monthly-issues.yml\n",
      "Added 10 chunks for file .github/workflows/dependabot-bot.yml\n",
      "Added 4 chunks for file .github/workflows/dependency-review.yml\n",
      "Added 8 chunks for file .github/workflows/dispatch-merge-main-to-live.yml\n",
      "Added 4 chunks for file .github/workflows/live-protection.yml\n",
      "Added 5 chunks for file .github/workflows/markdownlint.yml\n",
      "Added 4 chunks for file .github/workflows/no-response.yml\n",
      "Added 4 chunks for file .github/workflows/profanity-filter.yml\n",
      "Added 11 chunks for file .github/workflows/quest-bulk.yml\n",
      "Added 15 chunks for file .github/workflows/quest.yml\n",
      "Added 16 chunks for file .github/workflows/scorecards.yml\n",
      "Added 13 chunks for file .github/workflows/snippets5000.yml\n",
      "Added 5 chunks for file .github/workflows/stale.yml\n",
      "Added 8 chunks for file .github/workflows/version-sweep.yml\n",
      "Added 8 chunks for file .github/workflows/whats-new-automation.yml\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Ingest a GitHub repository and import into our vector store\n",
    "\n",
    "# Initialize the pipeline\n",
    "pipeline = DocumentPipeline(\n",
    "    vector_db_config=config_helper.vector_db_config,\n",
    "    embedding_config=config_helper.embedding_config\n",
    ")\n",
    "\n",
    "###Process git repository\n",
    "repository=\"https://github.com/dotnet/docs-aspire\"\n",
    "with tracer.start_as_current_span(f\"Starting ingesting {repository}\"):\n",
    "    pipeline.process_single_file(\"dotnet-docs-aspire.txt\",repository)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6855ef1f-7eca-4c4b-897d-e00d786b8c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/code/localrag.py:42: UserWarning: Api key is used with an insecure connection.\n",
      "  self.qdrant = QdrantClient(url=vector_db_config.url, api_key=vector_db_config.api_key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If I use Docker Compose, why should I care about .Net Aspire?\n",
      "\n",
      "Generated Answer:\n",
      " sections:\n",
      "  - name: Frequently asked questions\n",
      "    questions:\n",
      "      - question: |\n",
      "          Why choose .NET Aspire over Docker Compose for orchestration?\n",
      "        answer: |\n",
      "\n",
      "While Docker Compose is an excellent tool for running multiple projects or executables as containers, there are several reasons why you might prefer to use .NET Aspire (also known as the Orchestrator) for service discovery and orchestration:\n",
      "\n",
      "- **Declarative configuration**: .NET Aspire allows for more declarative configuration, making it easier to describe the desired state of your application without worrying about the underlying infrastructure.\n",
      "- **Better error handling**: With Docker Compose, if an environment variable is not set or the container fails, debugging can be challenging. In contrast, .NET Aspire provides better error handling and logging capabilities.\n",
      "- **Type safety**: The .NET Aspire SDK includes type-safe code generation, which helps ensure that your application's configuration and services are properly defined.\n",
      "- **Integration with other .NET projects**: If you're using other .NET applications as part of your project, the Orchestrator provides better integration and easier management of dependencies.\n",
      "\n",
      "However, it's worth noting that .NET Aspire does not replace Docker Compose entirely. You can still use Docker Compose to run containers from your orchestrator, but you'll need to define your application in a declarative way using .NET Aspire configuration files (e.g., `appsettings.json` or `docker-compose.yml`).\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Question: Is .Net Aspire an alternative to Kubernetes?\n",
      "\n",
      "Generated Answer:\n",
      "Based on the provided context, it appears that .NET Aspire is not directly an alternative to Kubernetes. Instead, .NET Aspire provides a superset of Kubernetes and additional features for building and deploying cloud-native applications. It includes orchestration and deployment capabilities, which are not available through using Kubernetes alone.\n",
      "\n",
      "In other words, .NET Aspire is designed to work in conjunction with Kubernetes to provide a more comprehensive solution for developing, deploying, and managing distributed applications. Therefore, it's not possible to say that .NET Aspire is an alternative to Kubernetes, but rather it builds upon and enhances the capabilities of Kubernetes.\n",
      "\n",
      "It's worth noting that the text mentions \"deploy-to-Kubernetes\" in the context of production environment systems, which suggests that .NET Aspire may be used in conjunction with Kubernetes for deployment purposes, but it does not imply a direct alternative.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test our RAG Solution\n",
    "\n",
    "def demonstrate_local_rag(rag):\n",
    "    \"\"\"Demonstrate how to use the LocalRAG class.\"\"\"    \n",
    "    # Example questions to test\n",
    "    questions = [\n",
    "        \"If I use Docker Compose, why should I care about .Net Aspire?\",\n",
    "        \"Is .Net Aspire an alternative to Kubernetes?\"\n",
    "    ]\n",
    "    with tracer.start_as_current_span(\"Entering questions loop.\"):\n",
    "        for question in questions:\n",
    "            print(f\"Question: {question}\")\n",
    "            # print(\"\\nRelevant chunks:\")\n",
    "            # with tracer.start_as_current_span(\"rag get chunks\"):\n",
    "            #     chunks = rag.get_relevant_chunks(question, k=5)\n",
    "            #     for i, chunk in enumerate(chunks, 1):\n",
    "            #         print(f\"\\nChunk {i}:\")\n",
    "            #         print(f\"Source: {chunk.metadata.get('file_path', 'Unknown')}\")\n",
    "            #         print(f\"Content: {chunk.page_content[:200]}...\")\n",
    "                    \n",
    "            print(\"\\nGenerated Answer:\")\n",
    "            with tracer.start_as_current_span(\"Retrieve answers.\"):\n",
    "                answer = rag.retrieve_and_answer(question, k=6)\n",
    "                print(answer)\n",
    "                print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "rag = LocalRAG(\n",
    "    vector_db_config=config_helper.vector_db_config,\n",
    "    embedding_config=config_helper.embedding_config, \n",
    "    chat_config=config_helper.chat_config\n",
    ")\n",
    "with tracer.start_as_current_span(\"Starting demo\"):\n",
    "    demonstrate_local_rag(rag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03d601-a3d6-4de9-80c9-6109d86594a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
