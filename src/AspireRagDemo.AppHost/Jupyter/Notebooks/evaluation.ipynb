{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb96146-c613-4f66-bdbf-61069d45e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is  used to evaluate perofrmance of our RAG ingestion and query pipeline.\n",
    "# Method:\n",
    "#   - Generated test data using a sample GitHub repository (offline process not in this notebook)\n",
    "#     - https://docs.ragas.io/en/stable/getstarted/rag_testset_generation/\n",
    "#   - Use our ingestion pipeline to parse the same reporisiroty and index in our vector store\n",
    "#   - Use RAGAS on teadt dataset + our answers fromn our RAG and visualise the mterics.\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(1, '/home/jovyan/work/code')\n",
    "from opentelemetry import trace\n",
    "from config import VectorDBConfig, EmbeddingConfig, ProcessingConfig, ChatConfig\n",
    "from config_helper import ConfigHelper\n",
    "from pipeline import DocumentPipeline\n",
    "from localrag import LocalRAG\n",
    "from TraceSetup import get_tracer, get_logger\n",
    "logger = get_logger()\n",
    "tracer = get_tracer()\n",
    "# We are using Aspire. Of course we will see the telemetry and logs in our dashboard!\n",
    "# see config_helper.py for the not to tidy details.\n",
    "config_helper = ConfigHelper(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e420af-10e9-41c0-8ab1-660add16a493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the test data\n",
    "# The test data is generated using the method described at: \n",
    "#    https://docs.ragas.io/en/stable/getstarted/rag_testset_generation/\n",
    "file_name= \"chatgpt-4o-latest_ReducedAspireDocs_50.pkl\" \n",
    "test_dataset =  pd.read_pickle(file_name)\n",
    "test_dataset.head()\n",
    "#for index, row in test_dataset.iterrows():\n",
    "#    print(row[\"reference_contexts\"])\n",
    "#    reference= row[\"reference\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d757e336-7b98-44af-ae16-716b15d446bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.ragas.io/en/latest/getstarted/rag_eval/#basic-setup\n",
    "evaluation_data=[]\n",
    "\n",
    "def query_using_rag(rag, question): \n",
    "    references=[]\n",
    "    with tracer.start_as_current_span(\"Getting answer and context.\"): \n",
    "        print(f\"Question: {question}\")\n",
    "        with tracer.start_as_current_span(\"rag get context\"):\n",
    "            chunks = rag.get_relevant_chunks(question, k=5)\n",
    "            for i, chunk in enumerate(chunks, 1):\n",
    "                references.append(chunk.page_content)\n",
    "        with tracer.start_as_current_span(\"Retrieve answers.\"):\n",
    "            answer = rag.retrieve_and_answer(question, k=5)\n",
    "            return (answer, references)\n",
    "\n",
    "rag = LocalRAG(\n",
    "    vector_db_config=config_helper.vector_db_config,\n",
    "    embedding_config=config_helper.embedding_config, \n",
    "    chat_config=config_helper.chat_config,\n",
    "    logger=logger,\n",
    "    tracer=tracer)\n",
    "\n",
    "with tracer.start_as_current_span(\"Starting demo\"):\n",
    "    for index, row in test_dataset.iterrows():\n",
    "        print(f\"Question {index}:\")\n",
    "        question = row[\"user_input\"]\n",
    "        reference= row[\"reference\"]\n",
    "        answer,contexts = query_using_rag(rag, question)        \n",
    "        print(answer[:150])\n",
    "        evaluation_data.append({\n",
    "            \"user_input\": question,\n",
    "            \"retrieved_contexts\": contexts,\n",
    "            \"response\": answer,\n",
    "            \"reference\": reference\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2a3306-7e39-404d-be32-c4b947167703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas import EvaluationDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ragas.metrics import (\n",
    "    LLMContextRecall, \n",
    "    Faithfulness, \n",
    "    FactualCorrectness, \n",
    "    AnswerRelevancy #,\n",
    "    #ContextRelevancy\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    #LLMContextRecall(), \n",
    "    Faithfulness(), \n",
    "    FactualCorrectness(),\n",
    "    AnswerRelevancy() #,\n",
    "    #ContextRelevancy()\n",
    "]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "evaluation_dataset = EvaluationDataset.from_list(evaluation_data)\n",
    "evaluator_llm = LangchainLLMWrapper(llm)\n",
    "\n",
    "with tracer.start_as_current_span(\"Starting model evaluation\"):\n",
    "    result = evaluate(dataset=evaluation_dataset,metrics=metrics,llm=evaluator_llm)\n",
    "    print(result)\n",
    "\n",
    "    \n",
    "#{'context_recall': 0.5450, 'faithfulness': 0.5920, 'factual_correctness': 0.3941}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557b4328-bd51-4faf-82f6-3a6aee657f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
